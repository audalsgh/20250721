# 21일차 NVIDIA 퀴즈풀고 Certification 받기
https://learn.nvidia.com/my-learning<br>
위 링크에서 확인가능.

## <NVIDIA Certiffication을 위한 Quiz 접속 과정>
링크접속 [딥러닝 institude](https://learn.nvidia.com/courses/course?course_id=course-v1:DLI+S-RX-02+V2-KR&unit=block-v1:DLI+S-RX-02+V2-KR+type@vertical+block@aabe204272214ba69309581d388b0734)<br>
Log-in<br>
Self paced courses<br>
View full catalog<br>
Getting started with AI on Jetson Nano 선택<br>
19페이지 이동 후, AI on Jetson Nano 의 Learn More 버튼 누르기<br>
Continue Learining<br>
Welcome<br>
(한글버전을 위해, 주소창에 -KR을 추가했음)<br>

<img width="2560" height="1006" alt="image" src="https://github.com/user-attachments/assets/c1c0d10c-40e5-4230-9cdf-1b2b24506ef2" /><br>
이미지 분류 마치고 10문제, 이미지 회귀 마치고 10문제 풀기.

이번 과정에서는 다음과 같은 간단한 시각적 질문에 대답할 수 있는 AI 프로젝트를 구축해 봅니다:
- 제 엄지손가락이 위를 향하고 있나요? 아니면 아래를 향하고 있나요?
- 제 얼굴의 표정이 행복해 보이나요? 아니면 슬퍼 보이나요?
- 제가 손가락 몇 개를 들고 있나요?
- 제 코는 어디에 있나요?<br>

비록 이러한 질문은들 어린이들에게는 대답하기 쉬운 간단한 질문임에도 불구하고 컴퓨터 비전으로 이미지를 해석하는 것은 많은 시나리오에서 답을 찾도록 조정될 수 있는 복잡한 컴퓨터 모델을 필요로 합니다.<br>
예를 들어 엄지 손가락을 위로 한 손이 카메라에서 다양한 각도와 거리에 있을 수 있고 다양한 배경 앞에서 포즈를 잡았을 수도 있고 다양한 손 종류에서 온 것일 수도 있으나, 여전히 엄지 손가락(Thumbs-up) 신호 입니다.<br>
효과적인 AI 모델은 이러한 다양한 시나리오에서 일반화(generalize)할 수 있어야 하며, 더 나아가 새로운 데이터가 주어져도 정확한 대답을 예측할 수 있어야 합니다.<br>

## Image Classfication
### AI and Deep Learning
**딥러닝 = 머신러닝에서 예제 분류를 해보고, 딥러닝때 새로운 이미지도 분류할수 있도록 훈련하는것.<br>**
인간으로서 우리는 우리의 경험을 바탕으로 우리가 보는 것을 일반화합니다.<br>
비슷한 방법으로 우리는 머신 러닝이라고 불리는 인공지능의 한 분야를 사용하여 경험을 바탕으로 많은 예제 데이터들을 일반화하고 분류할 수 있습니다.<br>
특히, 딥 뉴럴 네트워크 모델 또는 딥 러닝을 사용하여 이미지 데이터세트에서 관련 패턴을 인식하고 궁극적으로 새로운 이미지를 일치시켜 정답을 얻을 수 있습니다.<br>
<img width="1049" height="441" alt="image" src="https://github.com/user-attachments/assets/485372f1-50f8-465e-a84e-b629d2924523" /><br>
[인공지능, 머신러닝, 딥러닝의 차이점](https://blogs.nvidia.com/blog/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)

### Deep Learning Models
딥 러닝 모델은 입력을 출력에 매핑하도록 구성된 내부 파라미터(Parameter) 또는 가중치(Weight)를 가진 뉴럴 네트워크로 구성됩니다.<br>
이미지 분류에서 입력은 카메라 이미지의 픽셀이며 출력은 모델이 인식하도록 훈련된 가능한 범주(Category) 또는 클래스(Class)입니다.<br>
클래스는 1000개의 다른 객체일 수도 있고 또는 2개의 객체 만일 수도 있습니다. 여러 개의 레이블이 지정된 예제를 모델에 제공하여 이미지를 인식할 수 있도록 훈련(Train)해야 합니다.<br>
모델은 훈련한 후에는 실시간 데이터에서 실행하여 실시간으로 결과를 제공할 수 있어야 하며, 이 과정을 추론(Inference)이라고 합니다.<br>
<br>
훈련 전에는 가중치가 잘못되어 있으므로 모델이 이미지 입력에 대해 정확한 클래스를 지정하기가 어렵습니다.<br>
레이블이 지정된 이미지 예시는 반복적으로 학습 알고리즘(Learning Algorithm)을 사용하여 네트워크에 제출됩니다.<br>
네트워크에서 "잘못된" 답을 할당하면 (라벨이 일치하지 않는 경우) 학습 알고리즘은 가중치를 약간 조정합니다.<br>
계산 집약적인 반복 작업을 여러번 거칠 수록 정확도는 향상되어 모델이 입력 이미지에 대한 클래스를 안정적으로 결정할 수 있습니다.<br>
여러분이 알게 되겠지만, 입력되는 데이터는 좋은 모델을 만드는 핵심 중에 하나 입니다. 즉, 표시된 이미지의 배경, 각도, 또는 다른 "노이지한" 측면에도 관계 없이 잘 일반화를 할 수 있게 합니다.<br>
데이터 세트 또는 에포크(Epoch)를 추가로 통과할수록 모델 성능을 향상시킬 수 있기도 합니다.<br>
(= Epoch는 전체 학습 데이터를 한 번 모두 신경망에 통과시켜 학습시키는 과정)<br>

### Convolutional Neural Network (CNN)
딥 러닝은 Convolutional Neural Network (CNN) 모델에 의존하여 이미지를 예측된 분류로 변형합니다.<br>
CNN이란 Artificial neural network(인공 신경망)의 한 클래스이며 합성곱 레이어(컨볼루션 레이어)를 활용하여, 유용한 정보를 위해 인풋을 필터링하는 이미지 애플리케이션에서 선호되는 네트워크 입니다.<br>
<img width="1563" height="531" alt="image" src="https://github.com/user-attachments/assets/ddfe0aea-035f-4b16-950d-e90dc8a61c60" />

### Artificial Neural Network 인공 신경망
인공 신경망은 생물학적으로 영감을 받은 계산 모델로서, 인간의 뇌에 존재하는 뉴런의 네트워크를 본떠 만들어졌습니다.<br>
각 계층에서 네트워크는 가중치 입력 합에 비선형 함수를 적용하여 입력 데이터를 변형합니다.<br>
하나의 레이어(계층)에서 중간 출력 값은 다음 레이어의 입력으로 사용됩니다.<br>
반복된 변형을 통한 뉴럴 네트워크는 비선형 형상 (엣지와 모양) 의 여러 레이어들을 학습하고 마지막 레이어에어 결합하여 (더 복잡한) 객체의 예측 값을 생성합니다.<br>

### Convolutions
CNN 전용 컨볼루션 연산은 한 레이어의 입력 데이터(피쳐 맵)와 컨볼루션 커널 (필터)를 결합하여 다음 계층을 위한 변환된 피쳐 맵을 구성합니다.<br>
이미지 분류를 위한 CNN은 일반적으로 입력 계층(이미지), 형상 추출을 위한 일련의 숨겨진 레이어들 (컨볼루션), 그리고 "완전연결층" 출력 레이어(fully connected output layer, 분류)로 구성됩니다.<br>
CNN은 훈련을 받으면 분류의 요구 사항에 따라 가장 관련성이 높은 기능을 찾기 위해 자동으로 조정됩니다.<br>
예를 들어, CNN은 일반적인 물체 인식 작업에 직면했을 때는 물체의 모양에 대한 정보를 필터링하지만 새에 대한 인식 작업에 직면했을 때는 새의 색을 추출합니다.<br>
이것은 서로 다른 객체 클래스는 다른 모양을 가지고 있지만 새의 여러 종류는 여러 모양보다는 색깔에서 더 다를 가능성이 있다는 점에 대해 훈련을 통한 CNN의 인식이 바탕이 됩니다.<br>

### Accelerating CNNs using GPUs
CNN 모델을 훈련하고 훈련된 모델을 통해 추론을 실행하는 데 필요한 광범위한 연산 작업이 상당히 많을 수 있으므로 집중적인 연산 자원과 시간이 필요합니다.<br>
Caffe, TensorFlow, PyTorch와 같은 딥 러닝 프레임워크는 GPU에서 더 빠르게 실행되도록 최적화되어 있습니다.<br>
프레임워크는 GPU가 있는 경우 GPU의 병렬 처리 기능을 활용하여 훈련 및 추론 작업을 가속화 합니다.<br>
<br>
젯슨 나노는 128 코어의 NVIDIA Maxwell GPU를 포함하고 있습니다.<br>
풀 트레이닝 프레임워크를 실행할 수 있기 때문에, 전이학습(Transfer Learning)을 통해 네트워크를 재학습할 수도 있습니다.<br>
전이 학습은 이번 교육 과정에서 실습 프로젝트에서 활용할 예정입니다.<br>
젯슨 나노는 저렴한 플랫폼에서 딥 러닝과 인공 지능을 실험할 수 있게 해줍니다.<br> 
젯슨 나노 성능에 대해 더 자세한 내용은 링크속 문서를 참고. [젯슨 나노 성능 문서 링크](https://developer.nvidia.com/blog/jetson-nano-ai-computing/)<br>

### CNN 아키텍처 - ResNet
이미지 분류 및 회귀를 위해서 개발자들이 활용할 수 있는 세계적인 수준의 CNN 아키텍처는 많이 있습니다.<br>
PyTorch와 다른 프레임워크에서는 유명한Imagenet Large Scale Visual Recognition Challenge (ILSVRC)의 과거 우승 솔루션의 사전 훈련 모델들에 액세스할 수 있는 기능이 포함되어 있습니다.<br>
이 챌린지에서 연구원들은 정확하게 객체와 장면을 분류하고 감지할 수 있도록 서로 경쟁합니다.<br>
2015년도에는 ResNet이 이미지 분류, 감지, 지역화 부분에서 상을 휩쓸었습니다.<br>
이번 프로젝트에서는 ResNet 중 가장 작은 버전인 ResNet-18을 사용할 예정입니다.<br>
<img width="1097" height="624" alt="image" src="https://github.com/user-attachments/assets/84e42b1f-174b-4e3a-890d-432c853fe55a" /><br>

### Residual Networks
[Deep Residual Learning for Image Recognition 연구 논문](https://arxiv.org/pdf/1512.03385)은 왜 이 아키텍쳐가 효과적인지에 대한 인사이트를 제공하고 있습니다.<br>
ResNet은 딥러닝에서 레이어가 깊어질수록 학습이 어려워지는 문제를 해결한 아키텍쳐이다.<br>
```python
기존 구조:
입력 → Layer1 → Layer2 → 출력

ResNet 구조 (Residual Block):
입력 ────────────────┐
     ↓               │
   Layer1 → Layer2 → + → 출력
```
(입력에서 출력으로 직결되는 선이 shortcut connection)<br>
입력 그대로 유지하는 게 정답인 경우, 그냥 shortcut을 통해 그대로 전달하면 되서 효율적이다!<br>
ResNet은 하나 이상의 레이어를 건너 뛰는 "shortcut connections"를 통합하는 빌딩블록으로 만들어진 residual network입니다.<br>
<img width="128" height="440" alt="image" src="https://github.com/user-attachments/assets/491ec8f2-92d6-4b21-82d8-8f99f1137965" /><br>

이 shortcut 결과는 건너 뛴 레이어들의 결과들에 추가 됩니다.<br>
저자는 이 기술은 네트워크를 최적화하기에 용이하게 만들어 주고 크게 향상된 뎁스에도 더 높은 정확도 향상을 얻을 수 있음을 입증하였습니다.<br>
ResNet 아키텍처는 18개의 레이어 깊이에서 152개의 레이어 깊이까지 다양한 범위를 가지고 있습니다.<br>
우리는 여기서 가장 작은 네트워크인 ResNet-18을 사용하고 이 것은 젯슨 나노에 적합한 성능과 효율적인 크기와의 균형을 제공합니다.<br>

### Transfer Learning (전이 학습)
PyTorch는 [ImageNet 2012 classification dataset](https://image-net.org/challenges/LSVRC/2012/browse-synsets)에서 훈련된 사전 훈련된 ResNet-18 모델을 포함하고 있습니다.<br>
다시 말해서 모델은 이미 1000개의 다른 개체들을 인식할 수 있습니다!<br>
훈련된 뉴럴 네트워크 내에는 윤곽선, 곡선, 선 및 이미지의 식별 가능한 특징을 찾는 레이어들이 있습니다.<br>
기존 모델 훈련 시 학습된 중요한 이미지 특징들들은 우리의 분류 작업을 위해 재사용 가능합니다.<br>
<br>
우리는 ResNet-18 모델을 구성하는 18개의 마지막 네트워크 레이어를 수정하여 모두 10개 미만의 클래스를 포함하도록 이번 프로젝트에 맞게 조정할 것 입니다.<br>
ResNet-18 모델의 마지막 레이어는 완전히 연결된 (fully connected, fc) 레이어로 512개의 입력으로 풀링(pooled)되고 평탄화(flatten)되어 1000개의 가능한 출력 클래스로 연결됩니다.<br> 
우리는(512,1000)레이어를 클래스에 맞는 레이어로 교체 합니다. 예를 들어 3개의 클래스만 필요한 경우, 최종 레이어는 (512, 3)가 되어 각 512개의 입력이 3개의 출력 클래스 각각에 완전히 연결됩니다.<br>
<br>
여러분은 수집한 이미지를 사용하여 이러한 3가지 클래스를 인식할 수 있도록 네트워크를 훈련해야 하지만,<br>
네트워크는 이미 대부분의 개체에 공통적인 기능을 인식하도록 학습되어 있기 때문에 훈련 과정은 이미 부분적으로는 수행된 것이라고 할 수 있습니다.<br> 
이전 훈련은 재사용 가능하며 새로운 프로젝트로 "transferred(이전)"할 수 있습니다.<br>

### Thumbs Project
[한국어 버전 링크](https://learn.nvidia.com/courses/course?course_id=course-v1:DLI+S-RX-02+V2-KR&unit=block-v1:DLI+S-RX-02+V2-KR+type@vertical+block@fe5761e3ad8846e39604a2b32332c1b6)
### Emotions Project
[한국어 버전 링크](https://learn.nvidia.com/courses/course?course_id=course-v1:DLI+S-RX-02+V2-KR&unit=block-v1:DLI+S-RX-02+V2-KR+type@vertical+block@ddb1ddbfd84d49f7b45c38c5f01b1090)

### 퀴즈 10문항
1. 머신 러닝에서 "분류(Classification)" 란 무엇입니까?<br>
-> 몇 개의 입력을 이산 출력 값에 매핑하고, 주어진 분류 집합에 대해 입력을 분류하고, 입력 영상의 레이블을 예측하는 모든 과정
2. 이미지 데이터를 수집할 때 유의해야 하는 핵심사항은 무엇입니까? 해당되는 모든 항목에 체크하십시오.<br>
-> 모델이 필수 특징들을 학습할 수 있도록 다양한 배경을 제공, 색 변화를 학습할 수 있도록 조명 설정을 변경, 레이블 오류가 최소한으로 적은 데이터를 수집하여 데이터에 아웃라이어 또는 노이즈를 줄일 수 있도록 합니다.
3. 본 과정에서 분류 프로젝트에서는 어떤 단계를 거치나요?<br>
-> 데이터 수집하기->모델 훈련하기->라이브 데모 해보기
4. 본 과정에서 분류 모델을 훈련하기 위해 어떤 딥 러닝 프레임워크가 사용되었습니까?<br>
-> PyTorch
5. 전이 학습(Transfer Learning)은 무엇인가요?<br>
-> 사전 훈련된 모델을 활용하여 우리는 새로운 데이터 세트에 대해서만 훈련하면 됩니다.
6. 프로젝트를 위해 사전 훈련된 ResNet-18 모델의 마지막 레이어를 수정했었습니다. 어떤 종류의 레이어였나요?<br>
-> Fully Connected Layer (완전히 연결된 레이어) **분류(classification)**를 위한 최종 출력층이며, 원래는 ImageNet 데이터셋(클래스 1000개) 기준으로 설계되어 있음.
7. 우리는 ResNet-18 아키텍처를 제공하는 PyTorch를 활용하였습니다. ResNet-18이 사전 훈련받은 데이터 세트는 무엇입니까?<br>
-> ImageNet
8. 노트북에 CATEGORIES라는 전역 변수가 있습니다. 만약에 우리가 이 리스트에 새로운 카테고리를 추가하는 경우, 이 분류 작업에 대해 뉴럴 네트워크의 출력 차수(Output dimension)은 어떻게 바뀌어야 하나요?<br>
-> 뉴럴 네트워크의 출력 차수(output dimension)에 .append("mad") 메소드로 새로 분류할 카테고리를 추가하여 4개의 출력 차수를 갖게된다.
9. 모델 훈련 시 어떤 최적화 도구(optimizer)를 활용하였습니까?<br>
-> Adam
10. "Emotions Project(감정 분류 프로젝트)"에 포함된 이미지 분류 클래스는 총 몇 개입니까?<br>
-> 4개
    
## Image Regression
이미지 입력을 이산적인(discrete) 출력 값(클래스)에 매핑하는 이미지 분류 애플리케이션과 달리 이미지 회귀 작업은 이미지 인풋 픽셀을 연속적인(continuous) 출력값에 매핑합니다.
### 연속적인 출력 값
본 과정의 회귀 프로젝트에서는 이러한 연속 출력 값은 nose (코)와 같이 얼굴에 있는 다양한 형상의 X와 Y 값으로 정의 합니다.<br>
이미지 스트림을 추적 위치에 매핑하는 것은 움직이는 로봇 공학에서 선을 따라가는 것과 같은 다른 응용 프로그램에서도 사용될 수 있습니다.<br>
그러나 회귀 모델이 할 수 있는 것은 추적 뿐만은 아닙니다. 출력 값은 조향(Steering) 값이나 카메라 이동 파라미터와 같이 상당히 다를 수도 있습니다.

### 마지막 레이어 변경하기
사전 훈련된 ResNet-18 네트워크의 마지막 레이어는 1000개의 출력 클래스에 매핑된 512개의 입력값을 가진 또는 (512,1000)의 완전히 연결된 (fully connected, fc) 레이어 입니다.<br>
이미지 분류값에서 전이학습을 사용하기 위해서는 애플리케이션에 따라 마지막 레이어가 단 몇 개의 클래스로 변경되었습니다. 예를 들어 훈련된 3개의 클래스가 있는 경우 우리는 fc 레이어를 (512,3)으로 변경하였습니다.<br>
출력은 512개의 입력 값이 3개의 클래스에 매핑된 완전히 연결된 레이어로서 뉴럴 네트워크의 마지막 레이어를 포함됩니다.

좌표를 예측하는 회귀 프로젝트의 경우, 각 범주에 대해서는 X 및 Y 값이라는 2 개의 값이 필요합니다. 즉 fc 레이어에는 두 배의 출력이 필요합니다.<br>
예를 들어 X와 Y의 출력이 모두 있는 3 개의 얼굴 형상(nose (코), left_eye (왼쪽 눈), right_eye (오른쪽 눈))이 있는 경우, fc 레이어의 경우 6개의 출력, 또는 (512,6)이 필요합니다.<br>
분류에서는 출력 값의 확률 분포를 확인하기 위해 소프트맥스(softmax) 함수를 사용하였습니다.<br>
회귀에서는 확률에 대해 훈련한 것이 아니라 실제 X, Y 출력 값에 대해 훈련하였기 때문에 실제 값을 유지하고자 합니다.

### 평가하기
분류와 회귀는 평가 방식에서도 다릅니다. 분류의 이산적인 값은 정확도, 즉 "올바른" 답변의 확률을 계산하여 정확도를 기반하여 평가할 수 있습니다.<br>
회귀 분석의 경우, 정답에 가능한 가깝게 근접하는 데 관심이 있습니다. 따라서 평균 제곱근 오차 (Root Mean Square Error, RMSE)를 활용할 수 있습니다.

### Face XY Project
[한국어 버전 링크](https://learn.nvidia.com/courses/course?course_id=course-v1:DLI+S-RX-02+V2-KR&unit=block-v1:DLI+S-RX-02+V2-KR+type@vertical+block@77afe36f5e884ee69f484fb49ee39054)

### 퀴즈 10문항
1. 분류(Classification)와 회귀(Regression)의 차이점은 무엇입니까?<br>
-> 분류는 이산 출력을 예측하는 데 사용되고, 회귀는 연속 출력을 찾는 데 사용됩니다.
2. 전체 훈련 데이트 세트를 사용할 수 있으며 모든 입력이 이미지 또는 비디오라고 가정해 봅니다. 다음 중 이미지 회귀에 적합한 출력 유형은 무엇일까요? 해당 되는 모든 항목에 체크하세요.<br>
-> 자율 주행 시 속도 및 스티어링 컨트롤 출력, 얼굴에서 코 위치 좌표
3. 프로젝트에서 캡처된 입력 이미지 채널의 크기와 숫자는 어떻게 되었습니까?<br>
-> Width=224, Height=224, Channels=3
4. 회귀 작업에 활용된 뉴럴 네크워크 아키텍처는 무엇이었습니까?<br>
-> ResNet-18
5. ResNet-18 아키텍처에 사용된 Layer는 몇 개 입니까?<br>
-> 18개 : 17 Convolutional layers and 1 Fully Connected layer
6. 아래의 파이썬 코드가 의미하는 바는 무엇입니까?<br>
`model = models.resnet18(pretrained=True)`<br>
-> ResNet-18 모델을 사전 훈련된 가중치를 사용하도록 정의하기 (전이 학습, transfer learning)
7. 아래의 파이썬 코드가 의미하는 바는 무엇입니까?<br>
`model.fc = torch.nn.Linear(512, 5)`<br>
-> 신경망 모델의 마지막 Fully Connected (FC) 레이어를 (입력 크기 512, 출력 크기 5인 완전연결 층) 출력 5개를 가지도록 교체한다.<br>
→ 즉, 512차원의 특성 벡터 → 5개의 클래스에 대한 점수 출력
8. XY 회귀 노트북에 CATEGORIES라는 전역 변수가 있습니다. 만약에 이 리스트에 새로운 카테고리를 하나 더 추가하는 경우, (x,y) 회귀 작업을 위한 뉴럴 네트워크의 차원은 어떻게 바뀌어야합니까?<br>
-> 출력 차원은 2 증가 합니다. 카테고리 1개 추가마다 x,y 좌표가 더 생겨야하므로 2차원 증가
9. 클라우드/서버급의 GPU와 젯슨 나노에서 딥 러닝 모델을 훈련하는 것은 어떤 차이점이 있습니까?<br>
-> 젯슨 나노는 472 GigaFLOPS를 가지고 있는 반면에 Tesla GPU P100 (예시) 서버급 GPU는 18.7 TeraFLOPS를 가지고 있어, 젯슨 나노의 딥 러닝 아키텍처 훈련 속도가 더 느립니다.<br>
-> 젯슨 나노는 4G의 메모리를 가지고 있는 반면 Tesla GPU P100 (예시) 서버급 GPU는 16GB GPU 메모리를 가지고 있습니다. 따라서, 서버급 GPU가 더 큰 배치 사이즈를 처리할 수 있습니다.<br>
-> 위 이유들로 인해, 훈련 시간이 클라우드/서버 급의 GPU 보다 깁니다.
10. 얼굴 XY 프로젝트에서 코의 위치를 추적하기 위해 모델에 몇 개의 출력이 필요합니까?<br>
-> 2개
